{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c791b088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 12:50:28.906924: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-22 12:50:28.923906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740214228.943887    9762 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740214228.950133    9762 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-22 12:50:28.971370: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5989121",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0164233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_summarization_model():\n",
    "    model_name = 't5-base'  # You can also use 't5-base' or 'bart-large-cnn'\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141add02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, tokenizer):\n",
    "    input_text = \"summarize: \" + text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46bac0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text, model, tokenizer):\n",
    "    inputs = preprocess_text(text, tokenizer)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64b623",
   "metadata": {},
   "source": [
    "### Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef97185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wikipedia_content(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        text_content = \"\"\n",
    "        for para in paragraphs:\n",
    "            text_content += para.text\n",
    "        return text_content\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f9d8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_wikipedia_page(url):\n",
    "    model, tokenizer = initialize_summarization_model()\n",
    "    \n",
    "    print(f\"Scraping content from {url}...\")\n",
    "    article_content = scrape_wikipedia_content(url)\n",
    "    \n",
    "    if article_content:\n",
    "        print(\"\\nGenerating summary...\")\n",
    "        summary = generate_summary(article_content, model, tokenizer)\n",
    "        return summary\n",
    "    else:\n",
    "        return \"Failed to retrieve article content.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af50abbd",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "368595fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping content from https://en.wikipedia.org/wiki/Statue_of_George_Washington_(Trenton,_New_Jersey)...\n",
      "\n",
      "Generating summary...\n",
      "\n",
      "Summary of the Wikipedia page:\n",
      "the sculpture depicts general George Washington in a pose taken from the 1851 painting . it was owned by the banker Mahlon Dickerson Eyre . the statue is currently in the mill hill neighborhood of the city of Trenton in Mercer County, new jersey .\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Statue_of_George_Washington_(Trenton,_New_Jersey)'  # Change this URL to any Wikipedia page you want to scrape\n",
    "summary = summarize_wikipedia_page(url)\n",
    "print(f\"\\nSummary of the Wikipedia page:\\n{summary}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
